{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance Trade Off\n",
    "\n",
    "In statistics and machine learning, the bias–variance tradeoff describes the relationship between a model's complexity, the accuracy of its predictions, and how well it can make predictions on previously unseen data that were not used to train the model. In general, as we increase the number of tunable parameters in a model, it becomes more flexible, and can better fit a training data set. It is said to have lower error, or bias. However, for more flexible models, there will tend to be greater variance to the model fit each time we take a set of samples to create a new training data set. It is said that there is greater variance in the model's estimated parameters.\n",
    "\n",
    "\n",
    "In Simple: ```The inability of the machine learning model to truly capture the relationship in the training data.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Evaluating your Machine Learning Model\n",
    "\n",
    "- The primary aim of the Machine Learning models is to learn from the given data and generate predictions based on the pattern observed during the learning process. However, our task doesn’t end there. We need to continuously make improvements to the models, based on the kind of results it generates. We also quantify the model’s performance using metrics like Accuracy, Mean Squared Error(MSE), F1-Score, etc and try to improve these metrics. This can often get tricky when we have to maintain the flexibility of the model without compromising on its correctness.<br><br><br>\n",
    "\n",
    "- A supervised Machine Learning model aims to train itself on the input variables(X) in such a way that the predicted values(Y) are as close to the actual values as possible (Modafinil). This difference between the actual values and predicted values is the error and it is used to evaluate the model. The error for any supervised Machine Learning algorithm comprises of 3 parts:<br><br><br>\n",
    "\n",
    "\n",
    "1. Bias error\n",
    "2. Variance error\n",
    "3. The noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "1. Bias Error: This happens when our model is too simple and misses the important relationships between inputs (like features of data) and outputs (like predictions). It's like having a too basic idea that doesn't capture all the complexities in the data.\n",
    "\n",
    "2. Variance Error: This occurs when our model is too sensitive to the specific data it learned from. It might learn the noise or random fluctuations in the data rather than the real patterns. This can make our predictions vary a lot if we use different datasets.\n",
    "\n",
    "3. Noise: This is the natural randomness or unpredictability in the data itself. It's something we can't control or remove completely. It's like the background noise that makes it harder to hear the real signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<WhatsApp Image 2024-07-25 at 00.53.06_04d35a56.jpg>)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
